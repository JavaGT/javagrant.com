{"title":"Robots that can assemble almost anything.","link":"http://www.bbc.co.uk/programmes/w3ct31zc","pubDate":"Thu, 01 Dec 2022 17:34:00 +0000","enclosure":{"url":"http://open.live.bbc.co.uk/mediaselector/6/redir/version/2.0/mediaset/audio-nondrm-download-rss-low/proto/http/vpid/p0dl6xxd.mp3","length":"20608000","type":"audio/mpeg"},"content":"<p>Researchers at MIT have made significant steps toward creating robots that could practically and economically assemble nearly anything, including things much larger than themselves, from vehicles to buildings to larger robots.  Many objects could be built from tiny identical lightweight pieces e.g. an airplane wing or a racing car, and this latest work is a big step towards a fully autonomous self-replicating robot assembly system. Two of the authors are Professor Neil Gershenfeld, Director of the Centre for Bits and Atoms, and doctoral student Amira Abdel-Rahman, they explain how these robots self-assemble.</p><p>War of words on Wikipedia.</p><p>We’ve reported on the disinformation on the War in Ukraine on Twitter and Facebook, now reporter Shiroma Silva looks at what’s happening on Wikipedia.  From paid editing, harassment of editors and using multiple online identities to push certain messages, Wikipedia entries are being pushed towards a pro-Kremlin stance.  It’s not the first time that these coordinated activities have happened.  Last year the Wikimedia Foundation banned seven editors linked to a mainland China group for editing articles with the objective of promoting “the aims of China”, potentially threatening the very foundations of Wikipedia.</p><p>Can AI predict suicide risk?</p><p>Predicting if someone is at risk of suicide is incredibly difficult and increasingly researchers are attempting to train AI to be able to do this.  However with data bias and complex medical histories of patients the AI being developed are not yet reliable.  Even if accurate machine learning can be created, will there be services in place for those patients identified as being at high risk of suicide?  Much needs to be considered before this type of diagnosis is used in patient care.  Joseph Early from Southampton University and Karen Kusuma from the Black Dog Institute at the University of South Wales in Australia explain more. </p><p>The programme is presented by Gareth Mitchell with expert commentary from Ghislaine Boddington.</p><p>Image: MIT - Swarm Robot \nCourtesy of the researchers at MIT</p><p>Studio Manager: Bob Nettles\nProducer: Ania Lichtarowicz</p>","contentSnippet":"Researchers at MIT have made significant steps toward creating robots that could practically and economically assemble nearly anything, including things much larger than themselves, from vehicles to buildings to larger robots.  Many objects could be built from tiny identical lightweight pieces e.g. an airplane wing or a racing car, and this latest work is a big step towards a fully autonomous self-replicating robot assembly system. Two of the authors are Professor Neil Gershenfeld, Director of the Centre for Bits and Atoms, and doctoral student Amira Abdel-Rahman, they explain how these robots self-assemble.\nWar of words on Wikipedia.\nWe’ve reported on the disinformation on the War in Ukraine on Twitter and Facebook, now reporter Shiroma Silva looks at what’s happening on Wikipedia.  From paid editing, harassment of editors and using multiple online identities to push certain messages, Wikipedia entries are being pushed towards a pro-Kremlin stance.  It’s not the first time that these coordinated activities have happened.  Last year the Wikimedia Foundation banned seven editors linked to a mainland China group for editing articles with the objective of promoting “the aims of China”, potentially threatening the very foundations of Wikipedia.\nCan AI predict suicide risk?\nPredicting if someone is at risk of suicide is incredibly difficult and increasingly researchers are attempting to train AI to be able to do this.  However with data bias and complex medical histories of patients the AI being developed are not yet reliable.  Even if accurate machine learning can be created, will there be services in place for those patients identified as being at high risk of suicide?  Much needs to be considered before this type of diagnosis is used in patient care.  Joseph Early from Southampton University and Karen Kusuma from the Black Dog Institute at the University of South Wales in Australia explain more. \nThe programme is presented by Gareth Mitchell with expert commentary from Ghislaine Boddington.\nImage: MIT - Swarm Robot \nCourtesy of the researchers at MIT\nStudio Manager: Bob Nettles\nProducer: Ania Lichtarowicz","guid":"urn:bbc:podcast:w3ct31zc","isoDate":"2022-12-01T17:34:00.000Z","itunes":{"author":"BBC World Service","subtitle":"Robots that can assemble almost anything a step closer.","summary":"<p>Researchers at MIT have made significant steps toward creating robots that could practically and economically assemble nearly anything, including things much larger than themselves, from vehicles to buildings to larger robots.  Many objects could be built from tiny identical lightweight pieces e.g. an airplane wing or a racing car, and this latest work is a big step towards a fully autonomous self-replicating robot assembly system. Two of the authors are Professor Neil Gershenfeld, Director of the Centre for Bits and Atoms, and doctoral student Amira Abdel-Rahman, they explain how these robots self-assemble.</p><p>War of words on Wikipedia.</p><p>We’ve reported on the disinformation on the War in Ukraine on Twitter and Facebook, now reporter Shiroma Silva looks at what’s happening on Wikipedia.  From paid editing, harassment of editors and using multiple online identities to push certain messages, Wikipedia entries are being pushed towards a pro-Kremlin stance.  It’s not the first time that these coordinated activities have happened.  Last year the Wikimedia Foundation banned seven editors linked to a mainland China group for editing articles with the objective of promoting “the aims of China”, potentially threatening the very foundations of Wikipedia.</p><p>Can AI predict suicide risk?</p><p>Predicting if someone is at risk of suicide is incredibly difficult and increasingly researchers are attempting to train AI to be able to do this.  However with data bias and complex medical histories of patients the AI being developed are not yet reliable.  Even if accurate machine learning can be created, will there be services in place for those patients identified as being at high risk of suicide?  Much needs to be considered before this type of diagnosis is used in patient care.  Joseph Early from Southampton University and Karen Kusuma from the Black Dog Institute at the University of South Wales in Australia explain more. </p><p>The programme is presented by Gareth Mitchell with expert commentary from Ghislaine Boddington.</p><p>Image: MIT - Swarm Robot \nCourtesy of the researchers at MIT</p><p>Studio Manager: Bob Nettles\nProducer: Ania Lichtarowicz</p>","explicit":"clean","duration":"2576"}}